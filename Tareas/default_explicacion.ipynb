{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para responder puedes crear las celdas que quieras, crear codigo, ponder imagenes, incluir imagenes adicionales, platicarlo con tus companneres, preguntar, usar ChatGPT o lo que sea. Solo asegurate de hacerlo explicable, entender lo que esta pasando y ser capaz de defender tus elecciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribe tu nombre y clave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre: Mateo De La Roche\n",
    "Clave: 190748"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responde las siguientes preguntas sobre los modelos (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Que modelo(s) no estan sobreajustando (overfitting) sin importar la metrica? \n",
    "La regresión logística, LDA, GBM no muestran sobreajuste en ninguna de las métricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Que modelos tienen mayor riesgo de sobreajustar (overfitting) dependiendo de la metrica? Y por que?\n",
    "Se puede ver que la regresión logística está sesgada a la clase mayoritaria ya que al balancear la función de perdida mejora su precisión\n",
    "Random Forest y KNN son los que más sobre ajustan. \n",
    "Con random forest se debe a que se basa en árboles de decisión, por lo que es más probable que sobreajuste.\n",
    "KNN por fuerza los clusters y no sabe cuando detener el cluster.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responde las siguientes preguntas generales (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Las metricas (todas, algunas?) de sub, over, ponderadas y sin sampleo son comparables entre si o no? (Cuales son comparables entre si y bajo que criterios?)\n",
    "La ROC es buena para distinguir cuando son clasificadores binarios, ya que solo nos dice que tan bien clasifica los verdaderos positivos y los falsos positivos. pero no es tan robusta. \n",
    "No podemos comparar todas las métricas ya que si tienes un dataset desbalanceado y tu métrica no toma en cuenta el desbalanceo, no es comparable con una que si lo toma en cuenta o con un modelo que tiene función de perdida balanceada.\n",
    "\n",
    "Podemos comparar la balanced accuracy de los modelos tanto como con pesos balanceados como en raw para ver que tanto mejora el modelo con el peso balanceado.\n",
    "\n",
    "Igual la métrica que se usa depende del caso de uso, podemos usar precision si queremos que nuestro modelo tenga pocos falsos positivos, o recall si queremos que tenga pocos falsos negativos.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Debes aplicar sub, over sampleo y poderacion al conjunto de test para poder comparar las metricas que se crearon durante el entrenamiento con las de test?\n",
    "No, ya que el conjunto de test es para ver que tan bien generaliza el modelo, por lo que no se debe modificar. Solo podríamos correr un modelo con función de perdida balanceada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Que metricas (incluyendo la matriz confusion) te parecen las mejores para elegir resultados y decidir que emodelo entrara a produccion? (y por que?)\n",
    "Si es clasificador binario la ROC es buena para ver que tan bien clasifica los verdaderos positivos y los falsos positivos.\n",
    "Matriz de confusión nos deja ver en donde falla o donde es bueno cada modelo.\n",
    "Y según el caso de uso precisión, recall o F1-score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Responde de acuerdo a tu criterio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Si yo fuera el banco y te mencionara que actualmente no tenemos un benchmark para que puedas comparar tu modelo cual seria tu propuesta de bechmark (modelo y metricas)?\n",
    "Propondría un naive classifier y algúna regressión simple o árbol de decisión sin finetunear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Que metodo utilizarias para produccion? Explica tus razones de manera extensiva, incluye la eleccion de algoritmo, metrica, tipo de sampleo, analisis de varainza y bias de resultados y utilidad para el banco. Osea basicamente convenceme de manera tecnica pq elegirias todo eso en la realidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta (Modelo con Explicabilidad)\n",
    "Arból de decisión o logistic regression.  ya que ambos son modelos interpretable y es posible entender como toman las decisiónes. No aplicaría ningún tipo de sampleo, sino que, usaría la función de perdida balanceada.\n",
    "¿por qué LR? Porque es un modelo interpretable y es fácil de explicar a los stakeholders. El banco puede decir porque se le negó el crédito a un cliente y no solo decir que el modelo lo decidió.\n",
    "* Modelo: Árbol de Decisión\n",
    "* Métrica Principal: AUC-ROC\n",
    "* Métrica Secundaria: Precisión, Recall, F1-score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respuesta (Modelo sin explicabilidad)\n",
    "Son mejores modelos y presentan mayor precisión, pero no son interpretables. Es recomendable usarlos ya que son capaces de detectar las relaciones no lineales en los datos, sin embargo, por lo mismo no es posible entender como toman las decisiones.\n",
    "¿por qué GBM? Porque es un modelo que tiene un buen desempeño y es robusto a outliers. también es capaz de manejar los datos desbalanceados. Contras, no puedes decir porque diste o negaste el crédito.\n",
    "* Modelo: Gradient Boosting Machine (GBM)\n",
    "* Métrica Principal: AUC-ROC\n",
    "* Métrica Secundaria: Precisión, Recall, F1-score"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
